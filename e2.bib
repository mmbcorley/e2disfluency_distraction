Automatically generated by Mendeley Desktop 1.16.1
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

=== NEW STUFF BELOW HERE

@article{arnold2000heaviness,
  title={Heaviness {vs.\@} Newness: The Effects of Structural Complexity and Discourse Status on Constituent Ordering},
  author={Arnold, Jennifer E and Losongco, Anthony and Wasow, Thomas and Ginstrom, Ryan},
  journal={Language},
  pages={28--55},
  year={2000},
  publisher={JSTOR}
}

@inproceedings{loy2016lying,
  title={Lying, in a Manner of Speaking},
  author={Loy, Jia E and Rohde, Hannah and Corley, Martin},
  booktitle={Proceedings of {S}peech {P}rosody 8},
  year={2016},
  editor={Jon Barnes and Alejna Brugos and Stefanie Shattuck-Hufnagel and Nanette Veilleux},
  pages={984--988},
  address={Boston, MA}
}

@article{bailey2003disfluencies,
  title={Disfluencies Affect the Parsing of Garden-Path Sentences},
  author={Bailey, Karl G D and Ferreira, Fernanda},
  journal={Journal of Memory and Language},
  volume={49},
  number={2},
  pages={183--200},
  year={2003},
  publisher={Elsevier}
}

@article{corley2011helps,
  title={Why um helps auditory word recognition: The temporal delay hypothesis},
  author={Corley, Martin and Hartsuiker, Robert J},
  journal={{PLoS} {ONE}},
  volume={6},
  number={5},
  pages={e19792},
  year={2011},
  publisher={Public Library of Science}
}


@Book{frankfurt05,
  author = 	 {Harry G Frankfurt},
  title = 	 {On Bullshit},
  publisher = 	 {Princeton University Press},
  year = 	 2005}

=== NEW STUFF ABOVE HERE

@article{Arciuli2010,
abstract = {Lying is a deliberate attempt to transmit messages thatmislead others. Analysis of language behaviors holds great promise as an objective method of detecting deception. The current study reports on the frequency of use and acoustic nature of “um” and “like” during laboratory-elicited lying versus truth- telling. Results obtained using a within-participants false opinion paradigm showed that instances of “um” occur less frequently and are of shorter duration during lying compared to truth-telling. There were no significant differences in relation to “like.” These findings contribute to our understanding of the linguistic markers of deception behavior. They also assist in our understanding of the role of “um” in communication more generally. Our results suggest that “um” may not be accurately conceptualized as a filled pause/hesitation or speech disfluency/error whose increased usage coincides with increased cognitive load or increased arousal during lying. It may instead carry a lexical status similar to interjections and form an important part of authentic, effortless communication, which is somewhat lacking during lying.},
author = {ARCIULI, JOANNE and MALLARD, DAVID and VILLAR, GINA},
doi = {10.1017/S0142716410000044},
file = {:home/josiah/Documents/Mendeley Desktop/Arciuli, Mallard, Villar - 2010 - “Um, I can tell you're lying” Linguistic markers of deception versus truth-telling in speech.pdf:pdf},
isbn = {0142-7164},
issn = {0142-7164},
journal = {Applied Psycholinguistics},
month = {jul},
number = {03},
pages = {397--411},
title = {{“Um, I can tell you're lying”: Linguistic markers of deception versus truth-telling in speech}},
volume = {31},
year = {2010}
}
@article{FoxTree1995,
abstract = {Speech disfluencies have different effects on comprehension depending on the type and placement of disfluency. Words following false starts (such as windmill after in the in the eleventh example is um in the a windmill) have longer word monitoring latencies than the same tokens with the false starts excised. The decremental effect seems to be limited to false starts that occur in the middle of sentences or after discourse markers. I suggest it is at these points that the repair process is most burdened by the false start. In contrast, words following repetitions (heart in of a of a heart) do not have longer word monitoring latencies than the same tokens with the repetitions excised. In two experiments, words following spontaneously produced repetitions have faster word monitoring latencies. Two other experiments suggest that this seeming repetition advantage is more likely the result of slowed monitoring after a phonological phrase disruption. Inserting repetitions where they did not occur in a manner that preserved the original phonological phrases resulted in neither an advantage nor a disadvantage or repeating. These studies provide a first glimpse at how speech disfluencies affect understanding, and also provide information about the types of comprehension models that can accommodate the effects of speech disfluencies.},
author = {{Fox Tree}, Jean E.},
doi = {10.1006/jmla.1995.1032},
file = {:home/josiah/Documents/Mendeley Desktop/Fox Tree - 1995 - The effects of false starts and repetitions on the processing of subsequent words in spontaneous speech.pdf:pdf},
isbn = {0749-596X},
issn = {0749596X},
journal = {Journal of Memory and Language},
month = {dec},
number = {6},
pages = {709--738},
title = {{The Effects of False Starts and Repetitions on the Processing of Subsequent Words in Spontaneous Speech}},
volume = {34},
year = {1995}
}
@article{Finlayson2012,
abstract = {Disfluency is a characteristic feature of spontaneous human speech, commonly seen as a consequence of problems with production. However, the question remains open as to why speakers are disfluent: Is it a mechanical by-product of planning difficulty, or do speakers use disfluency in dialogue to manage listeners' expectations? To address this question, we present two experiments investigating the production of disfluency in monologue and dialogue situations. Dialogue affected the linguistic choices made by participants, who aligned on referring expressions by choosing less frequent names for ambiguous images where those names had previously been mentioned. However, participants were no more disfluent in dialogue than in monologue situations, and the distribution of types of disfluency used remained constant. Our evidence rules out at least a straightforward interpretation of the view that disfluencies are an intentional signal in dialogue.},
author = {Finlayson, Ian R and Corley, Martin},
doi = {10.3758/s13423-012-0279-x},
file = {:home/josiah/Documents/Mendeley Desktop/Finlayson, Corley - 2012 - Disfluency in dialogue an intentional signal from the speaker.pdf:pdf},
issn = {1069-9384},
journal = {Psychonomic Bulletin {\&} Review},
keywords = {{\`{a}} lire},
month = {oct},
number = {5},
pages = {921--928},
pmid = {22696249},
title = {{Disfluency in dialogue: an intentional signal from the speaker?}},
volume = {19},
year = {2012}
}
@manual{rbase,
address = {Vienna, Austria},
author = {{R Core Team}},
organization = {R Foundation for Statistical Computing},
title = {{R: A Language and Environment for Statistical Computing}},
url = {https://www.r-project.org/},
year = {2016}
}
@article{Ferreira2004b,
abstract = {Disfluencies include editing terms such as uh and um as well as repeats and revisions. Little is known about how disfluencies are processed, and there has been next to no research focused on the way that disfluencies affect structure-building operations during comprehension. We review major findings from both computational linguistics and psycholinguistics, and then we summarize the results of our own work which centers on how the parser behaves when it encounters a disfluency. We describe some new research showing that information associated with misarticulated verbs lingers, and which adds to the large body of data on the critical influence of verb argument structures on sentence comprehension. The paper also presents a model of disfluency processing. The parser uses a Tree Adjoining Grammar to build phrase structure. In this approach, filled and unfilled pauses affect the timing of Substitution operations. Repairs and corrections are handled by a mechanism we term "Overlay," which allows the parser to overwrite an undesired tree with the appropriate, correct tree. This model of disfluency processing highlights the need for the parser to sometimes coordinate the mechanisms that perform garden-path reanalysis with those that do disfluency repair. The research program as a whole demonstrates that it is possible to study disfluencies systematically and to learn how the parser handles filler material and mistakes. It also showcases the power of Tree Adjoining Grammars, a formalism developed by Aravind Joshi which has yielded results in many different areas of linguistics and cognitive science. {\textcopyright} 2004 Cognitive Science Society, Inc. All rights reserved.},
author = {FERREIRA, F},
doi = {10.1016/j.cogsci.2003.10.006},
file = {:home/josiah/Documents/Mendeley Desktop/Ferreira, Lau, Bailey - 2004 - Disfluencies, language comprehension, and Tree Adjoining Grammars.pdf:pdf},
isbn = {0364-0213},
issn = {03640213},
journal = {Cognitive Science},
keywords = {Disfluencies,Parsing,Syntax,TAG},
month = {oct},
number = {5},
pages = {721--749},
title = {{Disfluencies, language comprehension, and Tree Adjoining Grammars}},
volume = {28},
year = {2004}
}
@article{lme4,
author = {Bates, Douglas and M{\"{a}}chler, Martin and Bolker, Ben and Walker, Steve},
doi = {10.18637/jss.v067.i01},
issn = {1548-7660},
journal = {Journal of Statistical Software},
number = {1},
pages = {1--48},
title = {{Fitting Linear Mixed-Effects Models Using lme4}},
volume = {67},
year = {2015}
}
@article{Lickley1998,
abstract = {Three experiments investigated listeners' ability to detect disfluency in spontaneous speech. All employed gated word recognition with judgments of disfluency for spontaneous utterances containing disfluencies and for three kinds of fluent control utterances from the same six speakers: repetitions of corrected recordings of original disfluent items, spontaneous fluent utterances loosely matched in structure to the disfluent items, and repetitions of those spontaneous fluent items. In Experiment 1, 120 stimuli were word-level gated and presented to 20 subjects for word identification and for judgments on whether the utterance was about to become disfluent. Listeners were unable to predict disfluency reliably. New subjects (N = 20, 43) judged whether the same utterances had already become disfluent at each word gate in Experiment 2 or at each 35 ms gate in Experiment 3. Subjects reliably detected existing disfluencies during the first word gate after the interruption and before they recognized the word. Though more common around disfluencies than at similar points in controls, failures of word identification were not reliably associated with detection. Results are discussed in the light of computational models of disfluency detection.},
author = {Lickley, R J and Bard, E G},
doi = {10.1177/002383099804100204},
file = {:home/josiah/Documents/Mendeley Desktop/Lickley, Bard - 1998 - When can listeners detect disfluency in spontaneous speech.pdf:pdf},
issn = {00238309},
journal = {Language and speech},
keywords = {d,sf,uency detection},
pages = {203--226},
pmid = {10194877},
title = {{When can listeners detect disfluency in spontaneous speech?}},
volume = {41 ( Pt 2)},
year = {1998}
}
@article{Barr2002,
abstract = {Past research has shown that when speakers refer to the same referent multiple times, they tend to standardize their descriptions by establishing linguistic precedents. In three experiments, we show that listeners reduce uncertainty in comprehension by taking advantage of these precedents. We tracked listeners' eye movements in a referential communication task and found that listeners identified referents more quickly when specific precedents existed than when there were none. Furthermore, we found that listeners expected speakers to adhere to precedents even in contexts where it would lead to referential overspecification. Finally, we provide evidence that the benefits of linguistic precedents are independent of mutual knowledge—listeners were not more likely to benefit from precedents when they were mutually known than when they were not. We conclude that listeners use precedents simply because they are available, not because they are mutually known.},
author = {Barr, Dale J. and Keysar, Boaz},
doi = {10.1006/jmla.2001.2815},
file = {:home/josiah/Documents/Mendeley Desktop/Barr, Keysar - 2002 - Anchoring Comprehension in Linguistic Precedents.pdf:pdf},
isbn = {0749-596X},
issn = {0749596X},
journal = {Journal of Memory and Language},
keywords = {comprehension,mutual knowledge,precedents,psycholinguistics,reference.},
number = {2},
pages = {391--418},
title = {{Anchoring Comprehension in Linguistic Precedents}},
volume = {46},
year = {2002}
}
@article{Clark1994,
abstract = {The problems that participants in conversation have, it is argued, are really joint problems and have to be managed jointly. The participants have three types of strategies for managing them. (1) They try to prevent foreseeable but avoidable problems. (2) They warn partners of foreseeable but unavoidable problems. And (3) they repair problems that have already arisen. Speakers and addressees coordinate actions at three levels of talk: (1) the speaker's articulation and the addressees' attention to that articulation; (2) the speaker's presentation of an utterance and the addressees' identification of that utterance; and (3) the speaker's meaning and the addressees' understanding of that meaning. There is evidence that the participants have joint strategies for preventing, warning about and repairing problems at each of these levels. There is also evidence that they prefer preventatives to warnings, and warnings to repairs, all other things being equal. ?? 1994.},
author = {Clark, Herbert H.},
doi = {10.1016/0167-6393(94)90075-2},
file = {:home/josiah/Documents/Mendeley Desktop/Clark - 1994 - Managing problems in speaking.pdf:pdf},
isbn = {1601676393},
issn = {01676393},
journal = {Speech Communication},
keywords = {Conversation,Disfluencies,Repairs,Speaking problems},
month = {dec},
number = {3-4},
pages = {243--250},
pmid = {17497252},
title = {{Managing problems in speaking}},
volume = {15},
year = {1994}
}
@article{Boomer1965,
abstract = {The occurrence of filled and unfilled pauses was examined with respect to their location in phonemic clauses. Both types of hesitation were most frequent after the first word in the clause, regardless of length. These data are regarded as directly challenging the transitional probability theory of hesitations. The phonemic clause is proposed as the encoding unit of speech at the grammatical level.},
author = {Boomer, Donald S},
doi = {Article},
file = {:home/josiah/Documents/Mendeley Desktop/Boomer - 1965 - Hesitation and grammatical encoding.pdf:pdf},
issn = {00238309},
journal = {Language and Speech},
number = {3},
pages = {148--58},
pmid = {5832573},
title = {{Hesitation and grammatical encoding}},
volume = {8},
year = {1965}
}
@article{Clark2002,
author = {Clark, H},
doi = {10.1016/S0010-0277(02)00017-3},
file = {:home/josiah/Documents/Mendeley Desktop/Clark, Tree - 2002 - Using ıt uh and ıt um in spontaneous speaking.pdf:pdf},
issn = {00100277},
journal = {Cognition},
keywords = {conversation,dialogue,disfluencies,language production,spontaneous speech,uh,um},
month = {may},
number = {1},
pages = {73--111},
title = {{Using uh and um in spontaneous speaking}},
volume = {84},
year = {2002}
}
@article{Arnold2007,
abstract = {Eye-tracking and gating experiments examined reference comprehension with fluent (Click on the red. . .) and disfluent (Click on [pause] thee uh red . . .) instructions while listeners viewed displays with 2 familiar (e.g., ice cream cones) and 2 unfamiliar objects (e.g., squiggly shapes). Disfluent instructions made unfamiliar objects more expected, which influenced listeners' on-line hypotheses from the onset of the color word. The unfamiliarity bias was sharply reduced by instructions that the speaker had object agnosia, and thus difficulty naming familiar objects (Experiment 2), but was not affected by intermittent sources of speaker distraction (beeps and construction noises; Experiments 3). The authors conclude that listeners can make situation-specific inferences about likely sources of disfluency, but there are some limitations to these attributions.},
author = {Arnold, Jennifer E. and Kam, Carla L Hudson and Tanenhaus, Michael K},
doi = {10.1037/0278-7393.33.5.914},
file = {:home/josiah/Documents/Mendeley Desktop/Arnold, Kam, Tanenhaus - 2007 - If you say thee uh you are describing something hard the on-line attribution of disfluency during refere.pdf:pdf},
isbn = {0278-7393 (Print)},
issn = {1939-1285},
journal = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
keywords = {1973,1975,an illustration of this,attribution inferences,disfluency,evaluate the referent of,expressions like,eye-tracking,in which,is reference comprehension,language comprehension is efficient,listeners typically begin to,marslen-wilson,reference comprehension},
number = {5},
pages = {914--930},
pmid = {17723069},
title = {{If you say thee uh you are describing something hard: The on-line attribution of disfluency during reference comprehension.}},
volume = {33},
year = {2007}
}
@article{Schachter1991,
abstract = {It is generally accepted that filled pauses ("uh," "er," and "um") indicate time out while the speaker searches for the next word or phrase. It is hypothesized that the more options, the more likely that a speaker will say "uh." The academic disciplines differ in the extent to which their subject matter and mode of thought require a speaker to choose among options. The more formal, structured, and factual the discipline, the fewer the options. It follows that lecturers in the humanities should use more filled pauses during lectures than social scientists and that natural scientists should use fewest of all. Observations of lecturers in 10 academic disciplines indicate that this is the case. That this is due to subject matter rather than to self-selection into disciplines is suggested by observations of this same set of lecturers all speaking on a common subject. In this circumstance, the academic disciplines are identical in the number of filled pauses used. (PsycINFO Database Record (c) 2010 APA, all rights reserved)},
author = {Schachter, Stanley and Christenfeld, Nicholas and Ravina, Bernard and Bilous, Frances},
doi = {10.1037/0022-3514.60.3.362},
file = {:home/josiah/Documents/Mendeley Desktop/Schachter et al. - 1991 - Speech disfluency and the structure of knowledge.pdf:pdf},
isbn = {0022-3514},
issn = {0022-3514},
journal = {Journal of Personality and Social Psychology},
number = {3},
pages = {362--367},
title = {{Speech disfluency and the structure of knowledge.}},
volume = {60},
year = {1991}
}
@article{Allopenna1998,
abstract = {Eye movements to pictures of four objects on a screen were monitored as participants followed a spoken instruction to move one of the objects, e.g., ''Pick up the beaker; now put it below the diamond'' (Experiment 1) or heard progressively larger gates and tried to identify the referent (Experiment 2). The distractor objects included a cohort competitor with a name that began with the same onset and vowel as the name of the target object (e.g., beetle), a rhyme competitor (e.g. speaker), and an unrelated competitor (e.g., carriage). In Experiment 1, there was clear evidence for both cohort and rhyme activation as predicted by continuous mapping models such as TRACE (McClelland and Elman, 1986) and Shortlist (Norris, 1994). Additionally, the time course and probabilities of eye movements closely corresponded to response probabilities derived from TRACE simulations using the Luce choice rule (Luce, 1959). In the gating task, which emphasizes word-initial information, there was clear evidence for multiple activation of cohort members, as measured by judgments and eye movements, but no suggestion of rhyme effects. Given that the same sets of pictures were present during the gating task as in Experiment 1, we conclude that the rhyme effects in Experiment 1 were not an artifact of using a small set of visible alternatives. {\"{i}}¿¿ 1998 Academic Press Current models of spoken word recognition the phonetic information becomes consistent assume that listeners evaluate the unfolding with only a single lexical candidate (Tyler, speech input against an activated set of lexical 1984). In addition, recognition time for spo-candidates which compete for recognition. ken words is affected by the number and fre-Compelling evidence for these assumptions quency of other words that differ by only a comes from studies demonstrating that the single phoneme (Goldinger, Luce, {\&} Pisoni, recognition time for a spoken word is strongly 1989; Luce, Pisoni, {\&} Goldinger, 1990). influenced by the set of words to which it is Although it is clear that multiple candidates phonetically similar (for a recent review see compete for recognition, it is less clear just Cutler, 1995). For example, the recognition how the competitor set is defined and how it time for polysyllabic content words is corre-is evaluated. Models of lexical access make lated with the point in the speech stream where different claims about the nature of the com-petitor set and about how tolerant the pro-cessing system is to phonological mismatches We thank Delphine Dahan, Kathy Eberhard, Julie Sed-between the incoming speech and potential ivy, and Michael Spivey-Knowlton for helpful sugges-lexical representations. tions, and Cynthia Connine, Steve Goldinger, and Dennis Norris for comments which substantially improved this},
author = {Allopenna, Paul D and Magnuson, James S and Tanenhaus, Michael K.},
doi = {10.1006/jmla.1997.2558},
file = {:home/josiah/Documents/Mendeley Desktop/Allopenna, Magnuson, Tanenhaus - 1998 - Tracking the Time Course of Spoken Word Recognition Using Eye Movements Evidence for C ontinuous.pdf:pdf},
isbn = {0749-596X},
issn = {0749596X},
journal = {Journal of Memory and Language},
number = {38},
pages = {419--439},
title = {{Tracking the Time Course of Spoken Word Recognition Using Eye Movements: Evidence for C ontinuous Mapping Models}},
volume = {38},
year = {1998}
}
@article{Clark1998,
abstract = {Speakers often repeat the first word of major constituents, as in, "I uh I wouldn't be surprised at that." Repeats like this divide into four stages: an initial commitment to the constituent (with "I"); the suspension of speech; a hiatus in speaking (filled with "uh"); and a restart of the constituent ("I wouldn't."). An analysis of all repeated articles and pronouns in two large corpora of spontaneous speech shows that the four stages reflect different principles. Speakers are more likely to make a premature commitment, immediately suspending their speech, as both the local constituent and the constituent containing it become more complex. They plan some of these suspensions from the start as preliminary commitments to what they are about to say. And they are more likely to restart a constituent the more their stopping has disrupted its delivery. We argue that the principles governing these stages are general and not specific to repeats.},
author = {Clark, Herbert H and Wasow, Thomas},
doi = {10.1006/cogp.1998.0693},
file = {:home/josiah/Documents/Mendeley Desktop/Clark, Wasow - 1998 - Repeating words in spontaneous speech.pdf:pdf},
isbn = {0010-0285},
issn = {00100285},
journal = {Cognitive Psychology},
month = {dec},
number = {3},
pages = {201--242},
pmid = {9892548},
title = {{Repeating Words in Spontaneous Speech}},
volume = {37},
year = {1998}
}
@article{Swerts2005,
abstract = {This paper describes two experiments on the role of audiovisual prosody for signalling and detecting meta-cognitive information in question answering. The first study consists of an experiment, in which participants are asked factual questions in a conversational setting, while they are being filmed. Statistical analyses bring to light that the speakers' Feeling of Knowing (FOK) is cued by a number of visual and verbal properties. It appears that answers tend to have a higher number of marked auditory and visual cues, including divergences from the neutral facial expression, when the FOK score is low, while the reverse is true for non-answers. The second study is a perception experiment, in which a selection of the utterances from the first study is presented to participants in one of three conditions: vision only, sound only, or vision + sound. Results reveal that human observers can reliably distinguish high FOK responses from low FOK responses in all three conditions, but that answers are easier than non-answers, and that a bimodal presentation of the stimuli is easier than the unimodal counterparts. {\textcopyright} 2005 Elsevier Inc. All rights reserved.},
author = {Swerts, Marc and Krahmer, Emiel},
doi = {10.1016/j.jml.2005.02.003},
file = {:home/josiah/Documents/Mendeley Desktop/Swerts, Krahmer - 2005 - Audiovisual prosody and feeling of knowing.pdf:pdf},
isbn = {0749-596X},
issn = {0749596X},
journal = {Journal of Memory and Language},
keywords = {Audiovisual prosody,Facial expressions,Feeling of another's knowing,Feeling of knowing,Question answering,Speech perception,Speech production,Tip of the tongue},
month = {jul},
number = {1},
pages = {81--94},
title = {{Audiovisual prosody and feeling of knowing}},
volume = {53},
year = {2005}
}
@article{Rossnagel2000,
abstract = {The boundary conditions of perspective!takin` were explored in two experiments[ Participants `ave instructions on the assembly of a machine model[ In Experiment I$\backslash$ co`nitive load was manipulated$\backslash$ and speakers `ave two instructions to different addressees with diver`ent knowled`e[ Unlike utterances produced under low load$\backslash$ instructions `iven under hi`h load were not adapted to the addressees[ Experiment II demonstrated that this load effect was partially compensated for by hi`h accountability[ Findin`s support a two!sta`e model of utterance plannin`] the controlled processes of monitorin` and adjustment operate on the output of a predominantly automatic sta`e of plannin`[ Co`nitive load impairs monitorin` and adjustment$\backslash$ and leads to {\{}standard| utterances that are not adapted to the addressee|s perspective.}},
author = {Rox?nagel, Christian},
doi = {10.1002/(SICI)1099-0992(200005/06)30:3<429::AID-EJSP3>3.0.CO;2-V},
file = {:home/josiah/Documents/Mendeley Desktop/Rossnagel - 2000 - Cognitive load and perspective-taking applying the automatic-controlled distinction to verbal communication.pdf:pdf},
isbn = {0046-2772},
issn = {0046-2772},
journal = {European Journal of Social Psychology},
month = {may},
number = {3},
pages = {429--445},
title = {{Cognitive load and perspective-taking: applying the automatic-controlled distinction to verbal communication}},
volume = {30},
year = {2000}
}
@article{Kelly2010,
abstract = {Gesture and speech are assumed to form an integrated system during language production. Based on this view, we propose the integrated-systems hypothesis, which explains two ways in which gesture and speech are integrated--through mutual and obligatory interactions--in language comprehension. Experiment 1 presented participants with action primes (e.g., someone chopping vegetables) and bimodal speech and gesture targets. Participants related primes to targets more quickly and accurately when they contained congruent information (speech: "chop"; gesture: chop) than when they contained incongruent information (speech: "chop"; gesture: twist). Moreover, the strength of the incongruence affected processing, with fewer errors for weak incongruities (speech: "chop"; gesture: cut) than for strong incongruities (speech: "chop"; gesture: twist). Crucial for the integrated-systems hypothesis, this influence was bidirectional. Experiment 2 demonstrated that gesture's influence on speech was obligatory. The results confirm the integrated-systems hypothesis and demonstrate that gesture and speech form an integrated system in language comprehension.},
author = {Kelly, Spencer D. and Ozyurek, A. and Maris, Eric},
doi = {10.1177/0956797609357327},
file = {:home/josiah/Documents/Mendeley Desktop/Kelly, Ozy{\"{u}}rek, Maris - 2010 - Two sides of the same coin speech and gesture mutually interact to enhance comprehension.pdf:pdf},
isbn = {1467-9280 (Electronic)$\backslash$r0956-7976 (Linking)},
issn = {0956-7976},
journal = {Psychological Science},
keywords = {Attention,Comprehension,Female,Gestures,Humans,Male,Semantics,Speech},
month = {feb},
number = {2},
pages = {260--267},
pmid = {20424055},
title = {{Two Sides of the Same Coin: Speech and Gesture Mutually Interact to Enhance Comprehension}},
volume = {21},
year = {2010}
}
@article{Pickering2004,
abstract = {Traditional mechanistic accounts of language processing derive almost entirely from the study of monologue. Yet, the most natural and basic form of language use is dialogue. As a result, these accounts may only offer limited theories of the mechanisms that underlie language processing in general. We propose a mechanistic account of dialogue, the interactive alignment account, and use it to derive a number of predictions about basic language processes. The account assumes that, in dialogue, the linguistic representations employed by the interlocutors become aligned at many levels, as a result of a largely automatic process. This process greatly simplifies production and comprehension in dialogue. After considering the evidence for the interactive alignment model, we concentrate on three aspects of processing that follow from it. It makes use of a simple interactive inference mechanism, enables the development of local dialogue routines that greatly simplify language processing, and explains the origins of self-monitoring in production. We consider the need for a grammatical framework that is designed to deal with language in dialogue rather than monologue, and discuss a range of implications of the account.},
author = {Pickering, Martin J. and Garrod, Simon},
doi = {10.1017/S0140525X04000056},
file = {:home/josiah/Documents/Mendeley Desktop/Pickering, Garrod - 2004 - Toward a mechanistic psychology of dialogue.pdf:pdf},
isbn = {0140-525X (Print)$\backslash$r0140-525X (Linking)},
issn = {0140-525X},
journal = {The Behavioral and brain sciences},
keywords = {common ground,dialogue,dialogue routines,language comprehension,language production,monitoring,perception-be-},
number = {2},
pages = {169--190; discussion 190--226},
pmid = {15595235},
title = {{Toward a mechanistic psychology of dialogue.}},
volume = {27},
year = {2004}
}
@article{Beattie1979,
abstract = {The aim of the present study was to attempt to elucidate the nature of the units of encoding involved in the generation of spontaneous speech, firstly through analysis of the distribution of hesitations in speech, and secondly through analysis of speaker gaze direction in conversation. These analyses suggested that both suprasentential units and simple clausal units are implicated in the encoding process. Moreover, evidence of encoding on a clausal basis was only obtained for speech produced during the planning phrases of the larger, suprasentential units.},
author = {Beattie, Geoffrey W.},
doi = {10.1515/ling.1979.17.1-2.61},
file = {:home/josiah/Documents/Mendeley Desktop/Beattie - 1979 - Planning units in spontaneous speech Some evidence from hesitation in speech and speaker gaze direction in conversation.pdf:pdf},
isbn = {0024-3949 U6 - ctx{\{}{\_}{\}}ver=Z39.88-2004{\{}{\&}{\}}ctx{\{}{\_}{\}}enc=info{\{}{\%}{\}}3Aofi{\{}{\%}{\}}2Fenc{\{}{\%}{\}}3AUTF-8{\{}{\&}{\}}rfr{\{}{\_}{\}}id=info:sid/summon.serialssolutions.com{\{}{\&}{\}}rft{\{}{\_}{\}}val{\{}{\_}{\}}fmt=info:ofi/fmt:kev:mtx:journal{\{}{\&}{\}}rft.genre=article{\{}{\&}{\}}rft.atitle=Planning+Units+in+Spontaneous+Speech{\{}{\%}{\}}3A+Some+Evidence+from+Hesitation+in+Speech+and+Speaker+Gaze+Direction+in+Conversation{\{}{\&}{\}}rft.jtitle=Linguistics{\{}{\%}{\}}3A+An+Interdisciplinary+Journal+of+the+Language+Sciences{\{}{\&}{\}}rft.au=Beattie{\{}{\%}{\}}2C+Geoffrey+W{\{}{\&}{\}}rft.date=1979-01-01{\{}{\&}{\}}rft.issn=0024-3949{\{}{\&}{\}}rft.e},
issn = {1613396X},
journal = {Linguistics},
number = {1-2},
pages = {61--78},
title = {{Planning units in spontaneous speech: Some evidence from hesitation in speech and speaker gaze direction in conversation}},
volume = {17},
year = {1979}
}
@article{Schober1995,
abstract = {When speakers describe locations, they must choose among taking their own perspective, their addressee's, a shared frame of reference, and a neutral frame of reference that avoids the issue, among other options. This study examines whether speakers choose spatial perspectives that minimize effort for themselves, for their partners, or for both. It also examines whether perspectives are taken for particular individuals, for the speaker or addressee, or for the person who knows the information to be communicated. Three possible models are proposed for exactly how descriptions in a particular perspective are more difficult when speaker and addressee view a scene from different offsets. In a communication task, speakers described locations on a complex display for addressees who shared their vantage point or were offset by 90 or 180. In these conversations, both partners either took the perspective of the person who did not know the location or used descriptions that helped them avoid choosing one or the other person's perspective. Speakers who shared their addressee's vantage point gave different descriptions than 180 and 90 offset speakers, who did not differ from each other reliably. This is consistent with a model that suggests that what is difficult is speaking nonegocentrically, regardless of the size of the offset.},
author = {Schober, Michael F.},
doi = {10.1080/01638539509544939},
file = {:home/josiah/Documents/Mendeley Desktop/Schober - 1995 - Speakers, addressees, and frames of reference Whose effort is minimized in conversations about locations.pdf:pdf},
issn = {0163-853X},
journal = {Discourse Processes},
month = {sep},
number = {2},
pages = {219--247},
title = {{Speakers, addressees, and frames of reference: Whose effort is minimized in conversations about locations?}},
volume = {20},
year = {1995}
}
@article{Lau2005,
abstract = {... DOI: 10.1080 / 01690960444000142 Ellen F. Lau a {\&} Fernanda Ferreira a * pages 633-666. Available online: 06 Mar 2007. ... $\backslash$n},
author = {Lau, Ellen F. and Ferreira, Fernanda},
doi = {10.1080/01690960444000142},
file = {:home/josiah/Documents/Mendeley Desktop/Lau, Ferreira - 2005 - Lingering effects of disfluent material on comprehension of garden path sentences.pdf:pdf},
issn = {0169-0965},
journal = {Language and Cognitive Processes},
month = {oct},
number = {5},
pages = {633--666},
title = {{Lingering effects of disfluent material on comprehension of garden path sentences}},
volume = {20},
year = {2005}
}
@article{Corley2007,
abstract = {Everyday speech is littered with disfluency, often correlated with the production of less predictable words (e.g., Beattie {\&} Butterworth [Beattie, G., {\&} Butterworth, B. (1979). Contextual probability and word frequency as determinants of pauses in spontaneous speech. Language and Speech, 22, 201-211.]). But what are the effects of disfluency on listeners? In an ERP experiment which compared fluent to disfluent utterances, we established an N400 effect for unpredictable compared to predictable words. This effect, reflecting the difference in ease of integrating words into their contexts, was reduced in cases where the target words were preceded by a hesitation marked by the word er. Moreover, a subsequent recognition memory test showed that words preceded by disfluency were more likely to be remembered. The study demonstrates that hesitation affects the way in which listeners process spoken language, and that these changes are associated with longer-term consequences for the representation of the message. {\textcopyright} 2006 Elsevier B.V. All rights reserved.},
author = {Corley, Martin and MacGregor, Lucy J. and Donaldson, David I.},
doi = {10.1016/j.cognition.2006.10.010},
file = {:home/josiah/Documents/Mendeley Desktop/Corley, MacGregor, Donaldson - 2007 - It's the way that you, er, say it Hesitations in speech affect language comprehension.pdf:pdf},
isbn = {0010-0277 (Print)$\backslash$r0010-0277 (Linking)},
issn = {00100277},
journal = {Cognition},
keywords = {Disfluency,ERPs,Language comprehension,Speech},
number = {3},
pages = {658--668},
pmid = {17173887},
title = {{It's the way that you, er, say it: Hesitations in speech affect language comprehension}},
volume = {105},
year = {2007}
}
@article{Dahan2001,
abstract = {In two experiments, eye movements were monitored as participants followed spoken instructions to click on and move pictures with a computer mouse. In Experiment 1, a referent picture (e.g., the picture of a bench) was presented along with three pictures, two of which had names that shared the same initial phonemes as the name of the referent (e.g., bed and bell). Participants were more likely to fixate the picture with the higher frequency name (bed) than the picture with the lower frequency name (bell). In Experiment 2, referent pictures were presented with three unrelated distractors. Fixation latencies to referents with high-frequency names were shorter than those to referents with low-frequency names. The proportion of fixations to the referents and distractors were analyzed in 33-ms time slices to provide fine-grained information about the time course of frequency effects. These analyses established that frequency affects the earliest moments of lexical access and rule out a late-acting, decision-bias locus for frequency. Simulations using models in which frequency operates on resting-activation levels, on connection strengths, and as a postactivation decision bias provided further constraints on the locus of frequency effects.},
author = {Dahan, Delphine and Magnuson, James S and Tanenhaus, Michael K.},
doi = {10.1006/cogp.2001.0750},
file = {:home/josiah/Documents/Mendeley Desktop/Dahan, Magnuson, Tanenhaus - 2001 - Time course of frequency effects in spoken-word recognition evidence from eye movements.pdf:pdf},
isbn = {0010-0285 (Print)$\backslash$r0010-0285 (Linking)},
issn = {00100285},
journal = {Cognitive Psychology},
keywords = {alternatives that compete,are those that most,as the sound pattern,backdrop of partially activated,closely,eye tracking,for recognition,lexical frequency,of a spoken word,recognition,spoken-word recognition,takes place against a,the most activated alternatives,unfolds over time},
month = {jun},
number = {4},
pages = {317--367},
pmid = {11368527},
title = {{Time Course of Frequency Effects in Spoken-Word Recognition: Evidence from Eye Movements}},
volume = {42},
year = {2001}
}
@article{Frazier2006,
abstract = {Words, like musical notes, are grouped together into phrases by their rhythmic and durational properties as well as their tonal pitch. This 'prosodic phrasing' affects the understanding of sentences. Many processing studies of prosody have investigated sentences with a single, grammatically required prosodic boundary, which might be interpreted strictly locally, as a signal to end the current syntactic unit. Recent results suggest, however, that the global pattern of prosodic phrasing is what matters in sentence comprehension, not just the occurrence or size of a single local boundary. In this article we claim that the impact of prosodic boundaries depends on the other prosodic choices a speaker has made. We speculate that prosody serves to hold distinct linguistic representations together in memory. {\textcopyright} 2006 Elsevier Ltd. All rights reserved.},
author = {Frazier, Lyn and Carlson, Katy and Clifton, Charles},
doi = {10.1016/j.tics.2006.04.002},
file = {:home/josiah/Documents/Mendeley Desktop/Frazier, Carlson, Clifton - 2006 - Prosodic phrasing is central to language comprehension.pdf:pdf},
isbn = {1364-6613 (Print)$\backslash$r1364-6613 (Linking)},
issn = {13646613},
journal = {Trends in Cognitive Sciences},
number = {6},
pages = {244--249},
pmid = {16651019},
title = {{Prosodic phrasing is central to language comprehension}},
volume = {10},
year = {2006}
}
@article{Kronmuller2007,
abstract = {When speakers refer to the same referent multiple times in a conversation, they tend to follow established patterns of usage, known as conversational precedents. Research has found that listeners expect speakers to follow precedents, and that this expectation guides their search for referents (Barr, D. J., {\&} Keysar, B. (2002). Anchoring comprehension in linguistic precedents. Journal of Memory and Language, 46, 391-418). Recently, Metzing and Brennan (2003) (Metzing, C., {\&} Brennan, S. E. (2003). When conceptual pacts are broken: partner-specific effects on the comprehension of referring expressions. Journal of Memory and Language, 49, 201-213) reported a speaker-specific effect for broken precedents that suggests early use of speaker information when precedents are broken. Results from two eyetracking experiments show that this speaker effect results from the late use of speaker information to recover from an early, partner-independent preemption effect. When a new description is heard, existing precedents preempt the mapping of the new description to an old referent. Later, listeners use speaker-information to inhibit precedents that are not known to the current speaker. Time-course data, as well as the results of a cognitive load manipulation, suggest that the preemption and speaker effects are supported by distinct processing systems. Our findings indicate that certain pragmatic effects in language comprehension are based on general expectations about language use, rather than assumptions about the beliefs and goals of particular speakers. ?? 2006 Elsevier Inc. All rights reserved.},
author = {Kronm{\"{u}}ller, Edmundo and Barr, Dale J.},
doi = {10.1016/j.jml.2006.05.002},
file = {:home/josiah/Documents/Mendeley Desktop/Kronmuller, Barr - 2007 - Perspective-free pragmatics Broken precedents and the recovery-from-preemption hypothesis.pdf:pdf},
isbn = {0749-596X},
issn = {0749596X},
journal = {Journal of Memory and Language},
keywords = {Common ground,Eye-tracking,Language comprehension,Pragmatics,Referential communication},
month = {apr},
number = {3},
pages = {436--455},
title = {{Perspective-free pragmatics: Broken precedents and the recovery-from-preemption hypothesis☆}},
volume = {56},
year = {2007}
}
@article{Brennan1996,
abstract = {When people in conversation refer repeatedly to the same object, they come to use the same terms. This phenomenon, called lexical entrainment, has several possible explanations. Ahistorical accounts appeal only to the informativeness and availability of terms and to the current salience of the object's features. Historical accounts appeal in addition to the recency and frequency of past references and to partner-specific conceptualizations of the object that people achieve interactively. Evidence from 3 experiments favors a historical account and suggests that when speakers refer to an object, they are proposing a conceptualization of it, a proposal their addresses may or may not agree to. Once they do establish a shared conceptualization, a conceptual pact, they appeal to it in later references even when they could use simpler references. Over time, speakers simplify conceptual pacts and, when necessary, abandon them for new conceptualizations.},
author = {Brennan, Susan E and Clark, Herbert H},
doi = {10.1037/0278-7393.22.6.1482},
file = {:home/josiah/Documents/Mendeley Desktop/Brennan, Clark - 1996 - Conceptual pacts and lexical choice in conversation.pdf:pdf},
isbn = {0278-7393},
issn = {1939-1285},
journal = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
keywords = {Choice Behavior,Female,Humans,Male,Verbal Behavior,Vocabulary},
number = {6},
pages = {1482--1493},
pmid = {8921603},
title = {{Conceptual pacts and lexical choice in conversation.}},
volume = {22},
year = {1996}
}
@article{FoxTree1997,
abstract = {In spontaneous speaking, the is normally pronounced as thuh, with the reduced vowel schwa (rhyming with the first syllable of about). But it is sometimes pronounced as thiy, with a nonreduced vowel (rhyming with see). In a large corpus of spontaneous English conversation, speakers were found to use thiy to signal an immediate suspension of speech to deal with a problem in production. Fully 81{\%} of the instances of thiy in the corpus were followed by a suspension of speech, whereas only 7{\%} of a matched sample of thuhs were followed by such suspensions. The problems people dealt with after thiy were at many levels of production, including articulation, word retrieval, and choice of message, but most were in the following nominal.},
author = {{Fox Tree}, Jean E.},
doi = {10.1016/S0010-0277(96)00781-0},
file = {:home/josiah/Documents/Mendeley Desktop/Fox Tree, Clark - 1997 - Pronouncing the as thee to signal problems in speaking.pdf:pdf},
isbn = {0010-0277 (Print)$\backslash$n0010-0277 (Linking)},
issn = {00100277},
journal = {Cognition},
month = {feb},
number = {2},
pages = {151--167},
pmid = {9141905},
title = {{Pronouncing “the” as “thee” to signal problems in speaking}},
volume = {62},
year = {1997}
}
@article{Smith1993,
author = {Smith, Vicki L. and Clark, Herbert H.},
doi = {10.1006/jmla.1993.1002},
file = {:home/josiah/Documents/Mendeley Desktop/Smith, Clark - 1993 - On the Course of Answering Questions.pdf:pdf},
issn = {0749596X},
journal = {Journal of Memory and Language},
month = {feb},
number = {1},
pages = {25--38},
title = {{On the Course of Answering Questions}},
volume = {32},
year = {1993}
}
@article{Brennan2001,
abstract = {Listeners often encounter disfluencies (like uhs and repairs) in spontaneous speech. How is comprehension affected? In four experiments, listeners followed fluent and disfluent instructions to select an object on a graphical display. Disfluent instructions included mid-word interruptions (Move to the yel-purple square), mid-word interruptions with fillers (Move to the yel-uh, purple square), and between-word interruptions (Move to the yellow-purple square). Relative to the target color word, listeners selected the target object more quickly, and no less accurately, after hearing mid-word interruptions with fillers than after hearing comparable fluent utterances as well as utterances that replaced disfluencies with pauses of equal length. Hearing less misleading information before the interruption site led listeners to make fewer errors, and fillers allowed for more time after the interrup-tion for listeners to cancel misleading information. The information available in disfluencies can help listeners compensate for disruptions and delays in spontaneous utterances.},
author = {Brennan, Susan E and Schober, Michael F},
doi = {10.1006/jmla.2000.2753},
file = {:home/josiah/Documents/Mendeley Desktop/Brennan, Schober - 2001 - How Listeners Compensate for Disfluencies in Spontaneous Speech.pdf:pdf},
issn = {0749596X},
journal = {Journal of Memory and Language},
keywords = {comprehension,disfluencies,fillers,paralinguistic cues.,parsing,pauses,repairs,spontaneous speech},
month = {feb},
number = {2},
pages = {274--296},
title = {{How Listeners Compensate for Disfluencies in Spontaneous Speech}},
volume = {44},
year = {2001}
}
@article{Oviatt1995,
abstract = {This research characterizes the spontaneous spoken disfluencies typical of human-computer interaction, and presents a predictive model accounting for their occurrence. Data were collected during three empirical studies in which people spoke or wrote to a highly interactive simulated system as they completed service transactions. The studies involved within-subject factorial designs in which the input modality and presentation format were varied. Spoken disfluency rates during human-computer interaction were documented to be substantially lower than rates typically observed during comparable human-human speech. Two separate factors, both associated with increased planning demands, were statistically related to higher disfluency rates: (1) length of utterance; and (2) lack of structure in the presentation format. Regression techniques demonstrated that a linear model based simply on utterance length accounted for over 77{\%} of the variability in spoken disfluencies. Therefore, design methods capable of guiding users speech into briefer sentences have the potential to eliminate the majority of spoken disfluencies. In this research, for example, a structured presentation format successfully eliminated 60-70{\%} of all disfluent speech. The long-term goal of this research is to provide empirical guidance for the design of robust spoken language technology.},
author = {Oviatt, Sharon},
doi = {10.1006/csla.1995.0002},
file = {:home/josiah/Documents/Mendeley Desktop/Oviatt - 1995 - Predicting spoken disfluencies during human–computer interaction.pdf:pdf},
issn = {08852308},
journal = {Computer Speech {\&} Language},
month = {jan},
number = {1},
pages = {19--35},
title = {{Predicting spoken disfluencies during human–computer interaction}},
volume = {9},
year = {1995}
}
@article{Shriberg1996,
author = {Shriberg, Elizabeth},
file = {:home/josiah/Documents/Mendeley Desktop/Shriberg - 1996 - Disfluencies in SWITCHBOARD.pdf:pdf},
journal = {Proceedings International Conference on Spoken Language Processing},
pages = {11--14},
title = {{Disfluencies in SWITCHBOARD}},
year = {1996}
}
@article{Bortfeld2001,
author = {Bortfeld, Heather and Leon, S. D. and Bloom, Jonathan E and Schober, M. F. and Brennan, S. E.},
doi = {10.1177/00238309010440020101},
file = {:home/josiah/Documents/Mendeley Desktop//Bortfeld et al. - 2001 - Disfluency Rates in Conversation Effects of Age, Relationship, Topic, Role, and Gender.pdf:pdf},
issn = {0023-8309},
journal = {Language and Speech},
month = {jun},
number = {2},
pages = {123--147},
title = {{Disfluency Rates in Conversation: Effects of Age, Relationship, Topic, Role, and Gender}},
volume = {44},
year = {2001}
}
@article{Barr2014,
abstract = {Intersubjectivity is one of the enduring mysteries in the study of language use: how can different people with different beliefs use language to arrive a common understand-ing? Despite pervasive ambiguity, people seem to communicate their intentions effectively; moreover, they seem to do so with relative ease. These observations suggest the existence of powerful constraints on language processing. What are these constraints, and how are they incorporated into the production and interpretation of utterances? One influential proposal has been that language users reduce ambiguity by producing and interpreting language against their common ground—the set of information},
author = {Barr, Dale J.},
file = {:home/josiah/Documents/Mendeley Desktop/Barr - 2014 - Perspective Taking and its Impostors in Language Use Four Patterns of Deception.pdf:pdf},
journal = {The Oxford Handbook of Language and Social Psychology},
pages = {98--110},
title = {{Perspective Taking and its Impostors in Language Use: Four Patterns of Deception}},
year = {2014}
}
@article{Brennan1995,
abstract = {In question-answering, speakers display their metacognitive states using filled pauses and prosody (Smith {\&} Clark, 1993). We examined whether listeners are actually sensitive to this information. Experiment 1 replicated Smith and Clark′s study; respondents were tested on general knowledge questions, surveyed about their FOK (feeling-of-knowing) for these questions, and tested for recognition of answers. In Experiment 2, listeners heard spontaneous verbal responses from Experiment 1 and were tested on their feeling-of-another′s-knowing (FOAK) to see if metacognitive information was reliably conveyed by the surface form of responses. For answers, rising intonation and longer latencies led to fewer FOAK ratings by listeners. For nonanswers, longer latencies led to higher FOAK ratings. In Experiment 3, electronically edited responses with 1-s latencies led to higher FOAK ratings for answers and lower FOAK ratings for nonanswers than those with 5-s latencies. Filled pauses led to lower ratings for answers and higher ratings for nonanswers than did unfilled pauses. There was no support for a filler-as-morpheme hypothesis, that "um" and "uh" contrast in meaning. We conclude that listeners can interpret the metacognitive information that speakers display about their states of knowledge in question-answering.},
author = {Brennan, S.E. and Williams, Maurice},
doi = {10.1006/jmla.1995.1017},
file = {:home/josiah/Documents/Mendeley Desktop/Brennan, Williams - 1995 - The feeling of another's knowing Prosody and filled pauses as cues to listeners about the metacognitive state.pdf:pdf},
isbn = {0749-596X},
issn = {0749596X},
journal = {Journal of Memory and Language},
month = {jun},
number = {3},
pages = {383--398},
title = {{The Feeling of Another′s Knowing: Prosody and Filled Pauses as Cues to Listeners about the Metacognitive States of Speakers}},
volume = {34},
year = {1995}
}
@incollection{Clark,
address = {Washington},
author = {Clark, Herbert H. and Brennan, Susan E.},
booktitle = {Perspectives on socially shared cognition.},
doi = {10.1037/10096-006},
file = {:home/josiah/Documents/Mendeley Desktop/Clark, Brennan - Unknown - Grounding in communication.pdf:pdf},
pages = {127--149},
publisher = {American Psychological Association},
title = {{Grounding in communication.}},
}
@article{Corley2011,
abstract = {Several studies suggest that speech understanding can sometimes benefit from the presence of filled pauses (uh, um, and the like), and that words following such filled pauses are recognised more quickly. Three experiments examined whether this is because filled pauses serve to delay the onset of upcoming words and these delays facilitate auditory word recognition, or whether the fillers themselves serve to signal upcoming delays in a way which informs listeners' reactions. Participants viewed pairs of images on a computer screen, and followed recorded instructions to press buttons corresponding to either an easy (unmanipulated, with a high-frequency name) or a difficult (visually blurred, low-frequency) image. In all three experiments, participants were faster to respond to easy images. In 50{\%} of trials in each experiment, the name of the image was directly preceded by a delay; in the remaining trials an equivalent delay was included earlier in the instruction. Participants were quicker to respond when a name was directly preceded by a delay, regardless of whether this delay was filled with a spoken um, was silent, or contained an artificial tone. This effect did not interact with the effect of image difficulty, nor did it change over the course of each experiment. Taken together, our consistent finding that delays of any kind help word recognition indicates that natural delays such as fillers need not be seen as 'signals' to explain the benefits they have to listeners' ability to recognise and respond to the words which follow them.},
author = {Corley, Martin and Hartsuiker, Robert J.},
doi = {10.1371/journal.pone.0019792},
editor = {Perc, Matjaz},
file = {:home/josiah/Documents/Mendeley Desktop/Corley, Hartsuiker - 2011 - Why um helps auditory word recognition The temporal delay hypothesis.pdf:pdf},
issn = {1932-6203},
journal = {PLoS ONE},
month = {may},
number = {5},
pages = {e19792},
pmid = {21611164},
title = {{Why Um Helps Auditory Word Recognition: The Temporal Delay Hypothesis}},
volume = {6},
year = {2011}
}
@article{Barr2010,
abstract = {When listeners hear a speaker become disfluent, they expect the speaker to refer to something new. What is the mechanism underlying this expectation? In a mouse-tracking experiment, listeners sought to identify images that a speaker was describing. Listeners more strongly expected new referents when they heard a speaker say 'um' than when they heard a matched utterance where the um was replaced by noise. This expectation was speaker-specific: it depended on what was new and old for the current speaker, not just on what was new or old for the listener. This finding suggests that listeners treat fillers as collateral signals.},
author = {Barr, Dale J. and Seyfeddinipur, Mandana},
doi = {10.1080/01690960903047122},
file = {:home/josiah/Documents/Mendeley Desktop/Barr, Seyfeddinipur - 2010 - The role of fillers in listener attributions for speaker disfluency.pdf:pdf},
issn = {0169-0965},
journal = {Language and Cognitive Processes},
keywords = {Common ground,Dialogue,Disfluency,Fillers,Perspective taking},
month = {may},
number = {4},
pages = {441--455},
title = {{The role of fillers in listener attributions for speaker disfluency}},
volume = {25},
year = {2010}
}
@article{Hostetter2011,
abstract = {Do the gestures that speakers produce while talking significantly benefit listeners' comprehension of the message? This question has been the topic of many research studies over the previous 35 years, and there has been little consensus. The present meta-analysis examined the effect sizes from 63 samples in which listeners' understanding of a message was compared when speech was presented alone with when speech was presented with gestures. It was found that across samples, gestures do provide a significant, moderate benefit to communication. Furthermore, the magnitude of this effect is moderated by 3 factors. First, effects of gesture differ as a function of gesture topic, such that gestures that depict motor actions are more communicative than those that depict abstract topics. Second, effects of gesture on communication are larger when the gestures are not completely redundant with the accompanying speech; effects are smaller when there is more overlap between the information conveyed in the 2 modalities. Third, the size of the effect of gesture is dependent on the age of the listeners, such that children benefit more from gestures than do adults. Remaining questions for future research are highlighted.},
author = {Hostetter, Autumn B},
doi = {10.1037/a0022128},
file = {:home/josiah/Documents/Mendeley Desktop/Hostetter - 2011 - When do gestures communicate A meta-analysis(3).pdf:pdf},
isbn = {0033-2909},
issn = {0033-2909},
journal = {Psychological bulletin},
keywords = {communication,comprehension,gesture},
number = {2},
pages = {297--315},
pmid = {21355631},
title = {{When do gestures communicate? A meta-analysis.}},
volume = {137},
year = {2011}
}
@book{Westerveld2007,
address = {Berlin, Heidelberg},
author = {Westerveld, Thijs and Vries, Arjen De and Jong, Franciska De},
booktitle = {Multimedia Retrieval},
doi = {10.1007/978-3-540-72895-5},
editor = {Blanken, Henk M. and Blok, Henk Ernst and Feng, Ling and de Vries, Arjen P.},
file = {:home/josiah/Documents/Mendeley Desktop//Westerveld, Vries, de Jong - 2007 - Generative Probabilistic Models.pdf:pdf},
isbn = {978-3-540-72894-8},
pages = {177--198},
publisher = {Springer Berlin Heidelberg},
title = {{Generative Probabilistic Models}},
year = {2007}
}
@article{Keysar2000,
author = {Keysar, Boaz and Barr, Dale J and Balin, Jennifer A and Brauner, Jason S},
doi = {10.1111/1467-9280.00211},
file = {:home/josiah/Documents/Mendeley Desktop/Keysar et al. - 2000 - Research Article TAKING PERSPECTIVE IN CONVERSATION The Role of Mutual Knowledge in Comprehension.pdf:pdf},
issn = {0956-7976},
journal = {Psychological Science},
month = {jan},
number = {1},
pages = {32--38},
title = {{Taking Perspective in Conversation: The Role of Mutual Knowledge in Comprehension}},
volume = {11},
year = {2000}
}
@article{Dahan2002,
abstract = {The role of accent in reference resolution was investigated by monitoring eye fixations to lexical competitors (e.g., candy and candle) as participants followed prerecorded instructions to move objects above or below fixed geometric shapes using a computer mouse. In Experiment 1, the first utterance instructed participants to move one object above or below a shape (e.g., "Put the candle/candy below the triangle") and the second utterance contained an accented or deaccented definite noun phrase which referred to the same object or introduced a new entity (e.g., "Now put the CANDLE above the square" vs. "Now put the candle ABOVE THE SQUARE"). Fixations to the competitor (e.g., candy) demonstrated a bias to interpret deaccented nouns as anaphoric and accented nouns as nonanaphoric. Experiment 2 used only accented nouns in the second instruction, varying whether the referent of this second instruction was the Theme of the first instruction (e.g., "Put the candle below the triangle") or the Goal of the first instruction (e.g., "Put the necklace below the candle"). Participants preferred to interpret accented noun phrases as referring to a previously mentioned nonfocused entity (the Goal) rather than as introducing a new unmentioned entity. {\textcopyright} 2002 Elsevier Science (USA). All rights reserved.},
author = {Dahan, Delphine and Tanenhaus, Michael K. and Chambers, Craig G},
doi = {10.1016/S0749-596X(02)00001-3},
file = {:home/josiah/Documents/Mendeley Desktop/Dahan, Tanenhaus, Chambers - 2002 - Accent and reference resolution in spoken-language comprehension.pdf:pdf},
isbn = {0749-596X},
issn = {0749596X},
journal = {Journal of Memory and Language},
keywords = {Accent,Eye movements,Prosody,Reference resolution},
month = {aug},
number = {2},
pages = {292--314},
title = {{Accent and reference resolution in spoken-language comprehension}},
volume = {47},
year = {2002}
}
@article{Lallgee1969,
abstract = {Filled pauses have been described as a product of anxiety, and have also been explained as attempts by the speaker to maintain control of the "floor". The latter hypothesis is tested directly, by altering the preesure on the subject to continue speaking. Possible confounding effects of anxiety are controlled for. Filled pauses do not increase, as pressure to continue speaking increases. It is suggested that the "control" hypothesis may apply only to monologues; evidence concerning the relative frequency of filled pauses in monologues and dialogues is presented.},
author = {Lallgee, M G and Cook, M},
doi = {10.1177/002383096901200102},
file = {:home/josiah/Documents/Mendeley Desktop/Lallgee, Cook - 1969 - An experimental investigation of the function of filled pauses in speech.pdf:pdf},
issn = {0023-8309},
journal = {Language and speech},
number = {1},
pages = {24--28},
pmid = {5789293},
title = {{An experimental investigation of the function of filled pauses in speech.}},
volume = {12},
year = {1969}
}
@article{Blank1988,
abstract = {This article argues that familiar metaphors are associated with the mental lexicon, where they are easily accessed. Metaphorical senses could simply be added to the lexicon, as idioms, or combined with literal senses by abstrac- tion. These approaches do not, as Lakoff and Johnson (1980) pointed out, account for systematicity. One can not only "grasp lectures," but "manipulate beliefs," "toss theories around," and 'Yuggle formulas." A third possible strategy is sense extension, where rules derive a figurative sense by considering the violated literal constraints. The experiment reported here investigated such familiar and systematic metaphors, comparing the time to recognize words used in systematic metaphors as opposed to literal and anomalous control sentences. The results suggest a stage model of processing, in which the second, failure-driven stage is obligatory: If processing using literal senses (including any senses that have been lexicalized by idiom addition or abstraction) fails, then automatically check for any applicable sense extension rules. Finally, a computational model of the various strategies for lexicalization},
author = {Blank, Glenn David},
doi = {10.1207/s15327868ms0301},
file = {:home/josiah/Documents/Mendeley Desktop/Blank - 1988 - Metaphors in the Lexicon.pdf:pdf},
isbn = {1092-6488},
issn = {1092-6488},
journal = {Metaphors and Symbolic Activity},
number = {1},
pages = {21--36},
title = {{Metaphors in the Lexicon}},
volume = {3},
year = {1988}
}
@article{Loy2016,
author = {Loy, Jia E. and Rohde, Hannah and Corley, Martin},
doi = {10.1111/cogs.12378},
file = {:home/josiah/Documents/Mendeley Desktop/Loy, Rohde, Corley - 2016 - Effects of disfluency in online interpretation of deception.pdf:pdf},
issn = {03640213},
journal = {Cognitive Science},
keywords = {Language understanding,Pragmatics,Psychology},
month = {may},
title = {{Effects of Disfluency in Online Interpretation of Deception}},
year = {2016}
}
@article{Mathot2012,
abstract = {In the present article, we introduce OpenSesame, a graphical experiment builder for the social sciences. OpenSesame is free, open-source, and cross-platform. It features a comprehensive and intuitive graphical user interface and supports Python scripting for complex tasks. Additional functionality, such as support for eyetrackers, input devices, and video playback, is available through plug-ins. OpenSesame can be used in combination with existing software for creating experiments.},
author = {Math{\^{o}}t, Sebastiaan and Schreij, Daniel and Theeuwes, Jan},
doi = {10.3758/s13428-011-0168-7},
file = {:home/josiah/Documents/Mendeley Desktop//Math{\^{o}}t, Schreij, Theeuwes - 2012 - OpenSesame an open-source, graphical experiment builder for the social sciences.pdf:pdf},
isbn = {1554-3528 (Electronic)$\backslash$n1554-351X (Linking)},
issn = {1554-3528},
journal = {Behavior Research Methods},
keywords = {Computer Graphics,Humans,Photic Stimulation,Programming Languages,Research,Social Sciences,Social Sciences: methods,Software,User-Computer Interface},
month = {jun},
number = {2},
pages = {314--324},
pmid = {22083660},
title = {{OpenSesame: An open-source, graphical experiment builder for the social sciences}},
volume = {44},
year = {2012}
}
@article{Arnold2004,
abstract = {Most research on the rapid mental processes of on-line language processing has been limited to the study of idealized, fluent utterances. Yet speakers are often disfluent, for example, saying "thee, uh, candle" instead of "the candle." By monitoring listeners' eye movements to objects in a display, we demonstrated that the fluency of an article ("thee uh" vs. "the") affects how listeners interpret the following noun. With a fluent article, listeners were biased toward an object that had been mentioned previously, but with a disfluent article, they were biased toward an object that had not been mentioned. These biases were apparent as early as lexical information became available, showing that disfluency affects the basic processes of decoding linguistic input.},
author = {Arnold, Jennifer E. and Tanenhaus, Michael K. and Altmann, Rebecca J. and Fagnano, Maria},
doi = {10.1111/j.0956-7976.2004.00723.x},
file = {:home/josiah/Documents/Mendeley Desktop/Arnold et al. - 2004 - The old and thee, uh, new Disfluency and reference resolution.pdf:pdf},
isbn = {0956-7976},
issn = {09567976},
journal = {Psychological Science},
month = {sep},
number = {9},
pages = {578--582},
pmid = {15327627},
title = {{The Old and Thee, uh, New}},
volume = {15},
year = {2004}
}

@article{depaulo2003cues,
  title={Cues to Deception},
  author={DePaulo, Bella M and Lindsay, James J and Malone, Brian E and Muhlenbruck, Laura and Charlton, Kelly and Cooper, Harris},
  journal={Psychological Bulletin},
  volume={129},
  number={1},
  pages={74},
  year={2003},
  publisher={American Psychological Association}
}

@article{Bond2006,
abstract = {We analyze the accuracy of deception judgments, synthesizing research results from 206 documents and 24,483 judges. In relevant studies, people attempt to discriminate lies from truths in real time with no special aids or training. In these circumstances, people achieve an average of 54{\%} correct lie-truth judgments, correctly classifying 47{\%} of lies as deceptive and 61{\%} of truths as nondeceptive. Relative to cross-judge differences in accuracy, mean lie-truth discrimination abilities are nontrivial, with a mean accuracy d of roughly .40. This produces an effect that is at roughly the 60th percentile in size, relative to others that have been meta-analyzed by social psychologists. Alternative indexes of lie-truth discrimination accuracy correlate highly with percentage correct, and rates of lie detection vary little from study to study. Our meta-analyses reveal that people are more accurate in judging audible than visible lies, that people appear deceptive when motivated to be believed, and that individuals regard their interaction partners as honest. We propose that people judge others' deceptions more harshly than their own and that this double standard in evaluating deceit can explain much of the accumulated literature.},
author = {Bond, Charles F and DePaulo, Bella M},
doi = {10.1207/s15327957pspr1003_2},
file = {:home/josiah/Documents/Mendeley Desktop/Bond, DePaulo - 2006 - Accuracy of deception judgments.pdf:pdf},
isbn = {1088-8683},
issn = {1088-8683},
journal = {Personality and social psychology review : an official journal of the Society for Personality and Social Psychology, Inc},
number = {3},
pages = {214--234},
pmid = {16859438},
title = {{Accuracy of deception judgments.}},
volume = {10},
year = {2006}
}
@article{Barr2013,
abstract = {Linear mixed-effects models (LMEMs) have become increasingly prominent in psycholinguistics and related areas. However, many researchers do not seem to appreciate how random effects structures affect the generalizability of an analysis. Here, we argue that researchers using LMEMs for confirmatory hypothesis testing should minimally adhere to the standards that have been in place for many decades. Through theoretical arguments and Monte Carlo simulation, we show that LMEMs generalize best when they include the maximal random effects structure justified by the design. The generalization performance of LMEMs including data-driven random effects structures strongly depends upon modeling criteria and sample size, yielding reasonable results on moderately-sized samples when conservative criteria are used, but with little or no power advantage over maximal models. Finally, random-intercepts-only LMEMs used on within-subjects and/or within-items data from populations where subjects and/or items vary in their sensitivity to experimental manipulations always generalize worse than separate F1 and F2 tests, and in many cases, even worse than F1 alone. Maximal LMEMs should be the 'gold standard' for confirmatory hypothesis testing in psycholinguistics and beyond. ?? 2012 Elsevier Inc.},
author = {Barr, Dale J. and Levy, Roger and Scheepers, Christoph and Tily, Harry J.},
doi = {10.1016/j.jml.2012.11.001},
file = {:home/josiah/Documents/Mendeley Desktop/Barr et al. - 2013 - Random effects structure for confirmatory hypothesis testing Keep it maximal.pdf:pdf},
isbn = {0749-596X (Print)$\backslash$r0749-596X (Linking)},
issn = {0749596X},
journal = {Journal of Memory and Language},
keywords = {Generalization,Linear mixed-effects models,Monte Carlo simulation,Statistics},
month = {apr},
number = {3},
pages = {255--278},
pmid = {24403724},
publisher = {Elsevier Inc.},
title = {{Random effects structure for confirmatory hypothesis testing: Keep it maximal}},
volume = {68},
year = {2013}
}
@article{Schachter1994,
abstract = {It has been demonstrated that humanists are far more Ukely to use filled pauses ("uh," "ah," or "um") during their lectures than are social or natural scientists This finding has been interpreted in terms of the hypothesis that filled pauses mdicate time out while the speaker searches for the next word or phrase Based on the assumption that the more options at a choice point, the more likely a speaker will say "uh," it is hypothesized that the humanities are characterized by richer vocabularies il e , more synonyms) than are the sci- ences An analysts of the number of dif- ferent words used in lectures and in pro- fessional publications indicates that this IS indeed the case Scientists consis- tently use fewer different words than do humanists Further, the number of dif- ferent words correlates positively with the frequency of saying "uh" during lec- tures These findings are not restricted to academics, for in newspaper ac- counts, journalists use fewer different words in stories about science than in stories about the arts $\backslash$n},
author = {Schachter, Stanley and Rauscher, Frances and Christenfeld, Nicholas and Crone, Kimberly Tyson},
doi = {10.1111/j.1467-9280.1994.tb00611.x},
file = {:home/josiah/Documents/Mendeley Desktop/Schachter, Rauscher - 1994 - The vocabularies of academia.pdf:pdf},
issn = {0956-7976},
journal = {Psychological Science},
month = {jan},
number = {1},
pages = {37--41},
title = {{THE VOCABULARIES OF ACADEMIA}},
volume = {5},
year = {1994}
}
@article{Alibali2001,
abstract = {Do speakers gesture to benefit their listeners? This study examined whether speakers use gestures differently when those gestures have the potential to communicate and when they do not. Participants watched an animated cartoon and narrated the cartoon story to a listener in two parts: one part in normal face-to-face interaction and one part with visibility between speaker and listener blocked by a screen. The session was videotaped with a hidden camera. Gestures were identified and classified into two categories: representational gestures, which are gestures that depict semantic content related to speech by virtue of handshape, placement, or motion, and beat gestures, which are simple, rhythmic gestures that do not convey semantic content. Speakers produced representational gestures at a higher rate in the face-to-face condition; however, they continued to produce some representational gestures in the screen condition, when their listeners could not see the gestures. Speakers produced beat gestures at comparable rates under both conditions. The findings suggest that gestures serve both speaker-internal and communicative functions.},
author = {Alibali, Martha W and Heath, Dana C and Myers, Heather J},
doi = {10.1006/jmla.2000.2752},
file = {:home/josiah/Documents/Mendeley Desktop/Alibali, Heath, Myers - 2001 - Effects of Visibility between Speaker and Listener on Gesture Production Some Gestures Are Meant to Be Se.pdf:pdf},
isbn = {0749-596X},
issn = {0749596X},
journal = {Journal of Memory and Language},
keywords = {bene t their listeners,communication,communicative,context,do speakers gesture to,gesture,many studies have demonstrated,narrative,spontaneous hand gestures have,that speakers},
month = {feb},
number = {2},
pages = {169--188},
title = {{Effects of Visibility between Speaker and Listener on Gesture Production: Some Gestures Are Meant to Be Seen}},
volume = {44},
year = {2001}
}
@article{Barr2008,
abstract = {A new framework is offered that uses multilevel logistic regression (MLR) to analyze data from 'visual world' eyetracking experiments used in psycholinguistic research. The MLR framework overcomes some of the problems with conventional analyses, making it possible to incorporate time as a continuous variable and gaze location as a categorical dependent variable. The multilevel approach minimizes the need for data aggregation and thus provides a more statistically powerful approach. With MLR, the researcher builds a mathematical model of the overall response curve that separates the response into different temporal components. The researcher can test hypotheses by examining the impact of independent variables and their interactions on these components. A worked example using MLR is provided. ?? 2007 Elsevier Inc. All rights reserved.},
author = {Barr, Dale J.},
doi = {10.1016/j.jml.2007.09.002},
file = {:home/josiah/Documents/Mendeley Desktop/Barr - 2008 - Analyzing 'visual world' eyetracking data using multilevel logistic regression.pdf:pdf},
isbn = {0749-596X},
issn = {0749596X},
journal = {Journal of Memory and Language},
keywords = {Eyetracking,Multilevel modeling,Statistics},
month = {nov},
number = {4},
pages = {457--474},
title = {{Analyzing ‘visual world' eyetracking data using multilevel logistic regression}},
volume = {59},
year = {2008}
}
@article{Lin2010,
abstract = {People commonly interpret others' behavior in terms of the actors' underlying beliefs, knowledge, or other mental states, thereby using their "theory of mind." Two experiments suggest that using one's theory of mind is a relatively effortful process. In both experiments, people reflexively used their own knowledge and beliefs to follow a speaker's instruction, but only effortfully used their theory of mind to take into account a speaker's intention to interpret those instructions. In Experiment 1, people with lower working memory capacity were less effective than people with larger working memory capacity in applying their theory of mind to interpret behavior. In Experiment 2, an attention-demanding secondary task reduced people's ability to apply their theory of mind. People appear to be reflexively mindblind, interpreting behavior in terms of the actor's mental states only to the extent that they have the cognitive resources to do so. ?? 2010 Elsevier Inc. All rights reserved.},
author = {Lin, Shuhong and Keysar, Boaz and Epley, Nicholas},
doi = {10.1016/j.jesp.2009.12.019},
file = {:home/josiah/Documents/Mendeley Desktop/Lin, Keysar, Epley - 2010 - Reflexively mindblind Using theory of mind to interpret behavior requires effortful attention.pdf:pdf},
isbn = {0022-1031},
issn = {00221031},
journal = {Journal of Experimental Social Psychology},
keywords = {Attention,Perspective taking,Social cognition,Theory of mind},
number = {3},
pages = {551--556},
publisher = {Elsevier Inc.},
title = {{Reflexively mindblind: Using theory of mind to interpret behavior requires effortful attention}},
volume = {46},
year = {2010}
}
@article{Fernald1991,
abstract = {Two studies investigated adults' use of prosodic emphasis to mark focused words in speech to infants and adults. In Exp 1, 18 mothers told a story to a 14-mo-old infant and to an adult, using a picture book in which 6 target items were the focus of attention. Prosodic emphasis was measured both acoustically and subjectively. In speech to infants, mothers consistently positioned focused words on exaggerated pitch peaks in utterance-final position, whereas in speech to adults prosodic emphasis was more variable. In Exp 2, 12 women taught another adult an assembly procedure involving familiar and novel terminology. In both studies, stressed words in adult-directed speech rarely coincided with pitch peaks. However, in infant-directed speech, mothers regularly used pitch prominence to convey primary stress. The use of exaggerated pitch peaks at the ends of utterances to mark focused words may facilitate speech processing for the infant. (PsycINFO Database Record (c) 2004 APA, all rights reserved)},
author = {Fernald, Anne and Mazzie, Claudia},
doi = {10.1037/0012-1649.27.2.209},
file = {:home/josiah/Documents/Mendeley Desktop/Fernald, Mazzie - 1991 - Prosody and focus in speech to infants and adults.pdf:pdf},
isbn = {0012-1649},
issn = {0012-1649},
journal = {Developmental Psychology},
number = {2},
pages = {209--221},
title = {{Prosody and focus in speech to infants and adults.}},
volume = {27},
year = {1991}
}
@article{Ferreira2004a,
abstract = {Spoken language contains disfluencies, which include editing terms such as uh and um as well as repeats and corrections. In less than ten years the question of how disfluencies are handled by the human sentence comprehension system has gone from virtually ignored to a topic of major interest in computational linguistics and psycholinguistics. We discuss relevant empirical findings and describe a computational model that captures how disfluencies influence parsing and comprehension. The research reviewed shows that the parser, which presumably evolved to handle conversations, deals with disfluencies in a way that is efficient and linguistically principled. The success of this research program reinforces the current trend in cognitive science to view cognitive mechanisms as adaptations to real-world constraints and challenges.},
author = {Ferreira, Fernanda and Bailey, Karl G.D.},
doi = {10.1016/j.tics.2004.03.011},
file = {:home/josiah/Documents/Mendeley Desktop/Ferreira, Bailey - 2004 - Disfluencies and human language comprehension.pdf:pdf},
isbn = {1364-6613 (Print)$\backslash$r1364-6613 (Linking)},
issn = {13646613},
journal = {Trends in Cognitive Sciences},
month = {may},
number = {5},
pages = {231--237},
pmid = {15120682},
title = {{Disfluencies and human language comprehension}},
volume = {8},
year = {2004}
}
@article{Krahmer2005,
abstract = {We describe two experiments on signaling and detecting uncertainty in audiovisual speech by adults and children. In the first study, utterances from adult speakers and child speakers (aged 7 – 8) were elicited and annotated with a set of six audiovisual features. It was found that when adult speakers were uncertain they were more likely to produce fillers, delays, high intona- tion, eyebrow movements, and “funny faces.” The basic picture for the child speakers was somewhat similar, in that the presence of certain audiovisual cues correlated with uncertainty, but the differences were relatively small and less often significant. In the second study both adult and child judges watched responses from adult and child speakers selected from the first study to find out whether they were able to correctly estimate a speakers' level of uncertainty. It was found that both child and adult judges gave more accurate scores for answers from adult speakers than from child speakers and that child judges overall provided less accurate scores than adult judges. Acknowledgments:},
author = {Krahmer, E. and Swerts, M.},
doi = {10.1177/00238309050480010201},
file = {:home/josiah/Documents/Mendeley Desktop/Krahmer, Swerts - 2005 - How Children and Adults Produce and Perceive Uncertainty in Audiovisual Speech.pdf:pdf},
isbn = {0023830905048},
issn = {0023-8309},
journal = {Language and Speech},
keywords = {AUDIOVISUAL SPEECH,CHILDREN,FEELING OF ANOTHER'S KNOWING,FEELING OF KNOWING,QUESTION ANSWERING,SPEECH PERCEPTION,SPEECH PRODUCTION,UNCERTAINTY},
month = {mar},
number = {1},
pages = {29--53},
pmid = {16161471},
title = {{How Children and Adults Produce and Perceive Uncertainty in Audiovisual Speech}},
volume = {48},
year = {2005}
}
@article{Rochester1973,
abstract = {Studies of filled and silent pauses performed in the last two decades are reviewed in order to determine the significance of pauses for the speaker. Following a brief history, the theoretical implications of pause location are examined and the relevant studies summarized. In addition, the functional significance of pauses is considered in terms of cognitive, affective-state, and social interaction variables.},
author = {Rochester, S. R.},
doi = {10.1007/BF01067111},
file = {:home/josiah/Documents/Mendeley Desktop/Rochester - 1973 - The significance of pauses in spontaneous speech.pdf:pdf},
isbn = {0090-6905},
issn = {0090-6905},
journal = {Journal of Psycholinguistic Research},
number = {1},
pages = {51--81},
pmid = {24197795},
title = {{The significance of pauses in spontaneous speech}},
volume = {2},
year = {1973}
}
@article{Cook2009,
abstract = {[Speakers often have choices about how to structure their utterances. However, even though multiple alternatives may be acceptable in theory, often one of them will be preferred over the others. The question we explored here was what happens when speakers produce less preferred alternatives. We developed a new experimental paradigm to reliably elicit the propositional or double object dative with varying degrees of preference. We then used this paradigm to investigate how, given properties of the message, an individual speaker's preference for a particular structure affects how that utterance is produced. Speakers gestured more and were more likely to be disfluent when they chose less preferred structures. Thus, having a choice per se does not guarantee more successful production. Instead, production is facilitated when speakers choose more preferred alternatives.]},
author = {Cook, Susan Wagner and Jaeger, T Florian and Tanenhaus, Michael K},
file = {:home/josiah/Documents/Mendeley Desktop/Cook, Jaeger, Tanenhaus - 2009 - Producing Less Preferred Structures More Gestures, Less Fluency.pdf:pdf},
journal = {31st Annual Conference of the Cognitive Science Society},
keywords = {dative alternation,disfluencies,gesture,speech production},
pages = {62--67},
title = {{Producing Less Preferred Structures: More Gestures, Less Fluency}},
year = {2009}
}
@article{Eberhard1995,
author = {Eberhard, Kathleen M and Spivey-Knowlton, Michael J. and Sedivy, Julie C and Tanenhaus, Michael K},
doi = {10.1007/BF02143160},
file = {:home/josiah/Documents/Mendeley Desktop/Eberhard et al. - 1995 - Eye movements as a window into real-time spoken language comprehension in natural contexts.pdf:pdf},
issn = {0090-6905},
journal = {Journal of Psycholinguistic Research},
month = {nov},
number = {6},
pages = {409--436},
title = {{Eye movements as a window into real-time spoken language comprehension in natural contexts}},
volume = {24},
year = {1995}
}
@article{Heller2015,
abstract = {Upon hearing a disfluent referring expression, listeners expect the speaker to refer to an object that is previously unmentioned, an object that does not have a straightforward label, or an object that requires a longer description. Two visual-world eye-tracking experiments examined whether listeners directly associate disfluency with these properties of objects, or whether disfluency attribution is more flexible and involves situation-specific inferences. Since in natural situations reference to objects that do not have a straightforward label or that require a longer description is correlated with both production difficulty and with disfluency, we used a mini-artificial lexicon to dissociate difficulty from these properties, building on the fact that recently learned names take longer to produce than existing words in one's mental lexicon. The results demonstrate that disfluency attribution involves situation-specific inferences; we propose that in new situations listeners spontaneously infer what may cause production difficulty. However, the results show that these situation-specific inferences are limited in scope: listeners assessed difficulty relative to their own experience with the artificial names, and did not adapt to the assumed knowledge of the speaker.},
author = {Heller, D. and Arnold, Jennifer E. and Klein, N. and Tanenhaus, Michael K.},
doi = {10.1177/0023830914528107},
file = {:home/josiah/Documents/Mendeley Desktop/Heller et al. - 2015 - Inferring Difficulty Flexibility in the Real-time Processing of Disfluency.pdf:pdf},
issn = {0023-8309},
journal = {Language and Speech},
number = {2},
pages = {190--203},
title = {{Inferring Difficulty: Flexibility in the Real-time Processing of Disfluency}},
volume = {58},
year = {2015}
}
@article{Arnold2003,
author = {Arnold, Jennifer E and Fagnano, Maria and Tanenhaus, Michael K},
doi = {10.1023/A:1021980931292},
file = {:home/josiah/Documents/Mendeley Desktop/Arnold, Fagnano, Tanenhaus - 2003 - Disfluencies signal thee, um, new information.pdf:pdf},
issn = {00906905},
journal = {Journal of Psycholinguistic Research},
keywords = {cognitive{\_}science},
number = {1},
pages = {25--36},
title = {{Disfluencies Signal Theee, Um, New Information}},
volume = {32},
year = {2003}
}
@incollection{Barr2001,
abstract = {When we speak, we often encounter problems that compromise our ability to produce fluent speech. Sometimes we can't recall a word, do not feel confident in a proposition we wish to assert, or need extra time to plan a complex utterance. In conversation, these problems manifest themselves paralinguistically; for instance, as hesitations, filled pauses (e.g., in English, “um” and “uh”), or in prosodic contour. I hypothesize that these phenomena constitute a form of “vocal gesture” (Okrent, 2000), that, like manual gestures, can provide listeners with insight into the speaker's mind. I review three psycholinguistic experiments that suggest that these signals contribute to linguistic and conceptual coordination.},
author = {Barr, Dale J.},
booktitle = {Oralit{\'{e}} and gestualit{\'{e}}: Interactions et comportements multimodaux dans la communication},
editor = {Cav{\'{e}}, C and Gua{\"{i}}tella, I and Santi, S},
file = {:home/josiah/Documents/Mendeley Desktop/Barr - 2001 - Trouble in mind Paralinguistic indices of effort and uncertainty in communication.pdf:pdf},
isbn = {9782738469427},
keywords = {disfluencies,fillers,listene,r multimodal thesis},
pages = {597--600},
publisher = {Paris: L'Harmattan},
title = {{Trouble in mind: Paralinguistic indices of effort and uncertainty in communication}},
year = {2001}
}
@article{Barr2004,
abstract = {How do communities establish shared communication systems? The Common Knowledge view assumes that symbolic conventions develop through the accumulation of common knowledge regarding communication practices among the members of a community. In contrast with this view, it is proposed that coordinated communication emerges a by-product of local interactions among dyads. A set of multi-agent computer simulations show that a population of "egocentric" agents can establish and maintain symbolic conventions without common knowledge. In the simulations, convergence to a single conventional system was most likely and most efficient when agents updated their behavior on the basis of local rather than global, system-level information. The massive feedback and parallelism present in the simulations gave rise to phenomena that are often assumed to result from complex strategic processing on the part of individual agents. The implications of these findings for the development of theories of language use are discussed. ?? 2004 Cognitive Science Society, Inc. All rights reserved.},
author = {Barr, Dale J.},
doi = {10.1016/j.cogsci.2004.07.002},
file = {:home/josiah/Documents/Mendeley Desktop/Barr - 2004 - Establishing conventional communication systems Is common knowledge necessary.pdf:pdf},
isbn = {0364-0213},
issn = {03640213},
journal = {Cognitive Science},
keywords = {Common knowledge,Communication,Conventions,Multi-agent simulation,Pragmatics},
number = {6},
pages = {937--962},
title = {{Establishing conventional communication systems: Is common knowledge necessary?}},
volume = {28},
year = {2004}
}
@article{Zuckerman1981,
abstract = {People's beliefs about tile association of 19 visual and auditory cues with deception were assessed in one of two questionnaires: Subjects were asked to indicate the association of each cue with deception in their own behavior (self-perception condition) or in other people's behavior (otiler-perception condition). The 19 behaviors listed in the questionnaires had been previously examined in research on actual behaviors associated with deception; ten of these behaviors had also been examined in research on cues associated with judgment of deception. Stronger association between tile various cues and deception were obtained in the other-perception than in the self-perception condition, indicating that people believe they control their own deceptive behavior better than other people control theirs. Beliefs about the association of each behavior wittl deception (averaged across the two conditions and sex of respondents) correlated .11 witt{\~{}} the actual association of each cue with deception, and .44 with the association of each cue with judgment of deception. The possibility that the correspondence between beliefs about deception and actual cues to deception is higher for some specific types of lie-telling was discussed.},
author = {Zuckerman, Miron and Koestner, Richard and Driver, Robert},
doi = {10.1007/BF00987286},
file = {:home/josiah/Documents/Mendeley Desktop/Zuckerman, Koestner, Driver - 1981 - Beliefs about cues associated with deception.pdf:pdf},
isbn = {0191-5886; 1573-3653},
issn = {0191-5886},
journal = {Journal of Nonverbal Behavior},
number = {2},
pages = {105--114},
title = {{Beliefs about cues associated with deception}},
volume = {6},
year = {1981}
}
@article{Snodgrass1980,
abstract = {In this article we present a standardized set of 260 pictures for use in experiments investigating differences and similarities in the processing of pictures and words. The pictures are black-and-white line drawings executed according to a set of rules that provide consistency of pictorial representation. The pictures have been standardized on four variables of central relevance to memory and cognitive processing: name agreement, image agreement, familiarity, and visual complexity. The intercorrelations among the four measures were low, suggesting that they are indices of different attributes of the pictures. The concepts were selected to provide exemplars from several widely studied semantic categories. Sources of naming variance, and mean familiarity and complexity of the exemplars, differed significantly across the set of categories investigated. The potential significance of each of the normative variables to a number of semantic and episodic memory tasks is discussed.},
author = {Snodgrass, Joan Gay and Vanderwart, Mary},
doi = {10.1037/0278-7393.6.2.174},
file = {:home/josiah/Documents/Mendeley Desktop//Snodgrass, Vanderwart - 1980 - A standardized set of 260 pictures Norms for name agreement, image agreement, familiarity, and visual com.pdf:pdf},
isbn = {0096-1515 (Print)$\backslash$r0096-1515 (Linking)},
issn = {0096-1515},
journal = {Journal of Experimental Psychology: Human Learning {\&} Memory},
keywords = {Concept Formation,Discrimination Learning,Form Perception,Humans,Imagination,Mental Recall,Pattern Recognition,Semantics,Visual},
number = {2},
pages = {174--215},
pmid = {7373248},
title = {{A standardized set of 260 pictures: Norms for name agreement, image agreement, familiarity, and visual complexity.}},
volume = {6},
year = {1980}
}
@article{Chambers2002,
abstract = {A head-mounted eye-tracking methodology was used to investigate how linguistic and nonlinguistic informa- tion sources are combined to constrain referential interpretation. In two experiments, participants responded to in- structions to manipulate physical objects in a visual workspace. Instructions on critical trials contained definite noun phrases preceded by spatial prepositions (e.g., “Put the cube inside the can”). Experiment 1 established that the lexical–semantic constraints of the preposition inside immediately limited attention to objects compatible with those constraints (i.e., containers), suggesting that the referential context is dynamically restructured as sen- tence comprehension proceeds. Experiment 2 evaluated the additional influence of nonlinguistic constraints by varying the number of container objects that were large enough to hold the object being moved. The results indi- cated that attention was initially restricted to only those containers large enough to accommodate the object. This outcome suggests that referential candidates are continuously evaluated in terms of their relevance for the action denoted by the unfolding utterance. Overall, the findings are consistent with an expectation-driven interpretive system that rapidly integrates linguistic information with situation-specific constraints and knowledge of possible actions.},
author = {Chambers, Craig G and Tanenhaus, Michael K. and Eberhard, Kathleen M. and Filip, Hana and Carlson, Gregory N.},
doi = {10.1006/jmla.2001.2832},
file = {:home/josiah/Documents/Mendeley Desktop/Chambers et al. - 2002 - Circumscribing Referential Domains during Real-Time Language Comprehension.pdf:pdf},
isbn = {0749-596X},
issn = {0749596X},
journal = {Journal of Memory and Language},
keywords = {context,incremental processing,referential interpretation},
month = {jul},
number = {1},
pages = {30--49},
title = {{Circumscribing Referential Domains during Real-Time Language Comprehension}},
volume = {47},
year = {2002}
}
@article{FoxTree2001,
author = {{Fox Tree}, Jean E.},
doi = {10.3758/BF03194926},
file = {:home/josiah/Documents/Mendeley Desktop/Fox Tree - 2001 - Listeners' uses ofum anduh in speech comprehension.pdf:pdf},
issn = {0090-502X},
journal = {Memory {\&} Cognition},
month = {mar},
number = {2},
pages = {320--326},
title = {{Listeners' uses of um and uh in speech comprehension}},
volume = {29},
year = {2001}
}
@article{clark1996,
  title={Using language. 1996},
  author={Clark, Herbert H},
  journal={Cambridge University Press: Cambridge)},
  volume={952},
  pages={274--296},
  year={1996}
}
@article{DePaulo1982actual,
abstract = {Examined (a) specific verbal and paralinguistic cues that might reveal when deception is occurring or that might be used by perceivers in their attempts to detect deception and (b) the correspondence between actual and perceived cues to deception. 40 undergraduates served as liars and perceivers. As senders, Ss described either honestly or dishonestly other people they disliked; they also described the person they liked, pretending to dislike him or her. The verbal and nonverbal cues measured were nonfluencies, "um's" and "er's," rate, number of sentences, rate change, undifferentiating, simple differentiating, differentiating, dispositional, cognitive complexity, egocentric, mutual, other-oriented, excess other, positive, negative, neutral, excess positive, extremes, and "but's" and "yet's." The degree to which the cues actually were associated with deception corresponded significantly to the degree to which perceivers used those cues as signs of deceit. When Ss lied about people they really disliked, their descriptions were less positive and more neutral than when they honestly described people they really disliked. When feigning disliking, Ss uttered more nonfluencies than when expressing honest disliking. Descriptions that were spoken slowly and contained many "um's" and "er's" were judged by perceivers as deceptive. Expressions of liking that contained many "other" references, few self-references, and many nonspecific descriptors were also perceived to be deceptive. (27 ref) (PsycINFO Database Record (c) 2007 APA, all rights reserved)},
author = {DePaulo, Bella M and Rosenthal, Robert and Rosenkrantz, Judith and Green, Carolyn Rieder},
doi = {10.1207/s15324834basp0304_6},
file = {:home/josiah/Documents/Mendeley Desktop/DePaulo et al. - 1982 - Actual and perceived cues to deception A closer look at speech.pdf:pdf},
isbn = {0197-3533},
issn = {0197-3533},
journal = {Basic and Applied Social Psychology},
number = {4},
pages = {291--312},
title = {{Actual and perceived cues to deception: A closer look at speech}},
volume = {3},
year = {1982}
}
@article{Arciuli2009lies,
author = {Arciuli, J. and Villar, G. and Mallard, D.},
file = {:home/josiah/Documents/Mendeley Desktop/Arciuli, Villar, Mallard - 2009 - Lies , lies and more lies.pdf:pdf},
journal = {Proceedings of the 31st Annual Conference of the Cognitive Science Society},
keywords = {1978,and an important,bok,deception,described as threatening the,fabric of our society,lies,linguistic cues to deception,lying has been variously,moral},
pages = {2329--2334},
title = {{Lies , lies and more lies}},
year = {2009}
}
@article{Arciuli2010markers,
abstract = {Lying is a deliberate attempt to transmit messages thatmislead others. Analysis of language behaviors holds great promise as an objective method of detecting deception. The current study reports on the frequency of use and acoustic nature of “um” and “like” during laboratory-elicited lying versus truth- telling. Results obtained using a within-participants false opinion paradigm showed that instances of “um” occur less frequently and are of shorter duration during lying compared to truth-telling. There were no significant differences in relation to “like.” These findings contribute to our understanding of the linguistic markers of deception behavior. They also assist in our understanding of the role of “um” in communication more generally. Our results suggest that “um” may not be accurately conceptualized as a filled pause/hesitation or speech disfluency/error whose increased usage coincides with increased cognitive load or increased arousal during lying. It may instead carry a lexical status similar to interjections and form an important part of authentic, effortless communication, which is somewhat lacking during lying.},
author = {Arciuli, Joanne and Mallard, David and Villar, Gina},
doi = {10.1017/S0142716410000044},
file = {:home/josiah/Documents/Mendeley Desktop/Arciuli, Mallard, Villar - 2010 - “Um, I can tell you're lying” Linguistic markers of deception versus truth-telling in speech.pdf:pdf},
isbn = {0142-7164},
issn = {0142-7164},
journal = {Applied Psycholinguistics},
number = {03},
pages = {397--411},
title = {{“Um, I can tell you're lying”: Linguistic markers of deception versus truth-telling in speech}},
volume = {31},
year = {2010}
}
@article{Benus2006pauses,
abstract = {We use a corpus of spontaneous interview speech to investigate the relationship between the distributional and prosodic characteristics of silent and filled pauses and the intent of an interviewee to deceive an interviewer. Our data suggest that the use of pauses correlates more with truthful than with deceptive speech, and that prosodic features extracted from filled pauses themselves as well as features describing contextual prosodic information in the vicinity of filled pauses may facilitate the detection of deceit in speech.},
author = {Benus, Stefan and Enos, Frank and Hirschberg, Julia and Shriberg, Elizabeth and International, S R I and Park, Menlo},
doi = {10.1016/j.neuroimage.2009.05.032},
file = {:home/josiah/Documents/Mendeley Desktop/Benus et al. - 2006 - Pauses in Deceptive Speech(2).pdf:pdf},
issn = {10959572},
journal = {Speech Prosody},
pages = {2--5},
pmid = {19460447},
title = {{Pauses in Deceptive Speech}},
volume = {18},
year = {2006}
}




